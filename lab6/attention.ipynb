{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import v2\n",
    "from multiprocessing import active_children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(train: bool, transform: v2.Compose, download=False) -> Dataset:\n",
    "    return torchvision.datasets.CIFAR10(root='./data', train=train, download=download, transform=transform)\n",
    "\n",
    "basic_transform = v2.Compose([\n",
    "    v2.ToImage(), \n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)),\n",
    "])\n",
    "\n",
    "train_dataset = load_dataset(train=True, transform=basic_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_batch, labels = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3, 32, 32])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mean = torch.tensor([0.4914, 0.4822, 0.4465])\n",
    "std = torch.tensor([0.2470, 0.2435, 0.2616])\n",
    "\n",
    "def unnormalize_batch(batch: torch.Tensor):\n",
    "    unnormalized = batch.permute(0, 2, 3, 1)*std + mean\n",
    "    return unnormalized.permute(0, 3, 1, 2)\n",
    "    \n",
    "\n",
    "def visualize_patches(sequence_of_patches: torch.Tensor, patch_size: int, nrow: int) -> None:\n",
    "    sequence_length  = len(sequence_of_patches)\n",
    "    sequence_of_images = sequence_of_patches.reshape(sequence_length, 3,patch_size, patch_size)\n",
    "    \n",
    "    sequence_of_images = unnormalize_batch(sequence_of_images)\n",
    "    image_grid = torchvision.utils.make_grid(sequence_of_images, nrow=nrow, padding=1, pad_value=1)\n",
    "    \n",
    "    plt.imshow(image_grid.permute(1, 2, 0))\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 192)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Patch(nn.Module):\n",
    "\n",
    "    def __init__(self, patch_size: int, image_size: int, in_channels: int = 3):\n",
    "        super().__init__()\n",
    "\n",
    "        if image_size % patch_size:\n",
    "            raise AssertionError(\"Image size should be multiple of patch size\")\n",
    "\n",
    "        self.unfold = nn.Unfold((patch_size, patch_size), stride=patch_size)\n",
    "\n",
    "        self._patches_per_example = image_size*image_size // (patch_size*patch_size)\n",
    "        self._patch_vector_size = (patch_size*patch_size*in_channels)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        unfolded = self.unfold(x)\n",
    "        return unfolded.permute(0, 2, 1)\n",
    "    \n",
    "    @property\n",
    "    def patches_per_example(self):\n",
    "        return self._patches_per_example\n",
    "    \n",
    "    @property\n",
    "    def patch_vector_size(self):\n",
    "        return self._patch_vector_size\n",
    "\n",
    "    \n",
    "patching = Patch(8, 32)\n",
    "patching.patches_per_example, patching.patch_vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAY6klEQVR4nO3dSYxkh13H8Vd7VVdXr9PLrB577Jl4t2NiJSYiMQEJYgRGICFAgDjk5AgkFCElLBe4EAkhFBSBkBKQcgFBMCaKACVgBWErik0CceIlY4/Hs/Z0T3d11171Xj1uf458D08JRN/P+adXVa9e1a/e4V//Up7neSJJUpIk5e/1E5Ak/d9hKUiSgqUgSQqWgiQpWAqSpGApSJKCpSBJCpaCJClYCpKkYClIkoKlIEkKloIkKVgKkqRgKUiSgqUgSQqWgiQpWAqSpGApSJJCtegDvv8DH0S5g+5tlGuW5yi3VmdbRc+st1FuY43ljq0soly9UkO5X/vjv0O5T//mL6BcUmFv8f5BF+WmKTvPqyvLKFfOZig3mUxQbjweo9zvfuYfUe6TzzyNclmSodxw1Ee55ZUllEty9rjTyRTlKgm7TiuVCsp97FPPodyffZxdz+02+1zWak2UG8Hzkpfg7+cy+7zR9yPNSyj3zO/9KcoR3ilIkoKlIEkKloIkKVgKkqRgKUiSgqUgSQqWgiQpWAqSpGApSJJC4RPNr3zrFZQ7vM0mmlcb7HFLx1jwWNZhx2ttotxgzl5HP2OTwNTOO6+j3HDMJoGHI5abwdexxwZekya8AtOUTe5W4EQptX/tIsoNxwOUS+dskrU0Xke5MjzPMzgR3qqySeA+nMilLr/6NZRbWGD/IFAqs8nsEvyngaTMfj8Px2xCP52xXKUKvwAL5J2CJClYCpKkYClIkoKlIEkKloIkKVgKkqRgKUiSgqUgSQqWgiQpFD7R3KqxnaJJncXOwknls1tsJ/DmxhrKtejkZIm93tFkhHJUb8h2Eefw+dVbLfbAcEdzPmcTtMtwF3Y6Y7u667UFlKOaC2wCvlJnk8CTKbsOZil73xbg41bb7Lw06+zzlpbYBDdVg+c5Tdh5qcCvoUV4XvqDIcrNUjapXIbPr3fUZcECeacgSQqWgiQpWAqSpGApSJKCpSBJCpaCJClYCpKkYClIkoKlIEkKhU80N0spynU6bLns+ZOrKLfeYserzdkkcH+fTSZmczjRPGTnhZqO2ITl0gqbzK7Cydju4RE7Hryy1jpsorR31Ee56ZjlqFHvAOVyOGm72Gbvx2zK3t9yxnZX1xpsUjnL2HVfpSPD0DxjO5/rNfY6ynP2eZv02fubwN3kDbgzO52zCf3DQbG7sAnvFCRJwVKQJAVLQZIULAVJUrAUJEnBUpAkBUtBkhQsBUlSsBQkSaHwiea1BjtkC05YLrfZ7uCNpRrKZXM2AcpSSVKpwhHGcsH9W2UTpdUqOy/VnE1YZnDXdF5hr/fWLTZRms3YO9Ibsklgam/Ant9ia4kdcMJeRyVh70e5xCZtKw02sT4asIn/hRp8vVAbTtSPx2z392jGJprnCTt/3T47L90hmwjvw384GM+++7/bvVOQJAVLQZIULAVJUrAUJEnBUpAkBUtBkhQsBUlSsBQkScFSkCSFwieaN1bYZGKnxiaBm02WK1fYZGKrxSakZymbPJ3D3bx5Xuyu1dKcvd5syh53nrNJzBzu0s2rdZTrTQcol2XsOhhmbBKYSuHxegN2/q7tsx3StTJ73KU+mzCf3WTPb3TIJsLPHLsH5aha9RTKlTqHKDc52EO5fp9df4c9NtG8d8jej0vvsF3nWQX+Y0KBvFOQJAVLQZIULAVJUrAUJEnBUpAkBUtBkhQsBUlSsBQkScFSkCSFwieaT2y0UW6pznaULi6wydgSnMhN4E7WEtxZPBmxCdAynHym1jsdlGvDHddHh7sot7zEdvP2xuz9uHwNTp5O2GRnvdiB5qTBBl6Tao1Nsr59u4tyk5y93hrc0by8xK6XJ+57D8od3aBbzJkcrtZePsZ2jk+GLNfvs9/FjRo73ultdp43N7dQbueITVIXyTsFSVKwFCRJwVKQJAVLQZIULAVJUrAUJEnBUpAkBUtBkhQsBUlSKHyiea2zwB54eoByjRp7igsNNkk9GbFJ29mcTVyvrKyiXJ6zyVOqCne3zmZs0nZhcRHlru9OUO7Ny2yX7m6PnWe4Ajk5u1DsTtunH3sU5U4dZ+fvb15+E+VevHgT5dI525ldLbPrr9dlk+3DPrsOqHR2mwUz9s8AzSabQK7DHfALJXa8NGPX85nTJ1Gus892ORfJOwVJUrAUJEnBUpAkBUtBkhQsBUlSsBQkScFSkCQFS0GSFCwFSVIo5UWP2kqS/t/yTkGSFCwFSVKwFCRJwVKQJAVLQZIULAVJUrAUJEnBUpAkBUtBkhQK39H8yY/8KMqN9q+iXLXFdi+nacYed8qW/VZLbNC7VmE7Y2n7/s5fv4Jyn/jpd6Hcyuoyyk0z9npffOktlNs7YLtqU3gFTuAZvH+BXQd/9RrbIf3SM+9DuaVKHeW+eruFcl95+xbK7XR3UG5eYuclZ29bUk7nKPcPF9nr+OiP3I1yp05vo1wCP7/TKdthPp+z442nbGd2vcKu51aL7f7++F+8iHKEdwqSpGApSJKCpSBJCpaCJClYCpKkYClIkoKlIEkKloIkKVgKkqRQ+ETz6rENlltkk53lcg3lukcHKDcb9NnjZmwCdJ6wyc68VuypXlxl53mWNFHu1bdeR7nBZIByzWaD5ersvLTaCyi3WoEjudDLF2+iXDplr2OyfBzlNlbZ+1ZKllBulo5RbggnfAfDYle7T1P2vpVmbGI4YX80kNTKLJiXK+x4VXYdpBP2fuTwnwaK5J2CJClYCpKkYClIkoKlIEkKloIkKVgKkqRgKUiSgqUgSQqWgiQpFD7RnMAJ5FKN5ahGkx1vIWE7n6uwL8tllpvByWequcQmmvdu9lBuuMcmwu9aY5O2cGAzacJJ5QvnTqFcmT4wlK5uotzR0T7KVStdlOvU2W7e9VW22/jcPWdQ7tI7X0O5195gO9apRnWCcnnOrucULv8uV9nkfa3Ovl/mc/Y5n8OR61Lpu/+73TsFSVKwFCRJwVKQJAVLQZIULAVJUrAUJEnBUpAkBUtBkhQsBUlSKHyieTSeoVxpxnbBJgnb3ToYHKHcdMZ6MC2zyd3+kE1YHg3Z86MGY7YrOU/Z87vjGJuwPHeCTXYOx+x4J88/gnL1nE0qHxyy64/qnF5nwdtsh+/pbbajuTtg7+9d77oH5ZZW2eT40uq9KHewW+z1DD/mSQ1OepdzNqk8m8Nd7PAPCbIZeyFwNXSS5+5oliR9D1kKkqRgKUiSgqUgSQqWgiQpWAqSpGApSJKCpSBJCpaCJCkUPtGcldiEYJ6xyT860ddqtlBuscMmO6/vsonrS1dvoVy1Vuxk4u7ONZQb7+yi3D2bbFL5Qx88j3JvXruNcp2TbNf0sfVtlLu1u4Ny1AOPsInh8pydv3qZTT7f2mXvb7XZRbnd7g2Uu3ajj3K1Gtt1Tq0sdVBuNGKfo7zKfu+W4GjxHE4+l0tw9zK8DrLv/kCzdwqSpP9hKUiSgqUgSQqWgiQpWAqSpGApSJKCpSBJCpaCJClYCpKkUPhE88oK26GaVtlEc7/PdvPmMzZxeNg7RLnL79xEuX6fTYC2msX2741LbEJ1q1lHuZMnz6Lcyok7Ua7Wg0ttm2wS+NTDj7PD3WSTwNTW9hrKZQm7TgcDlju+wCa9pxk7z6U2+1yeap9Auc4KmzCn7rn3Asrd2mGT8rMSu67G0wnKJWU2WtxusN3u0xGcHK+z11Ek7xQkScFSkCQFS0GSFCwFSVKwFCRJwVKQJAVLQZIULAVJUrAUJEmh8InmXpdNHFanPZSrlWBvsZWnSbXCgsM+m3xe7bBdtSttNulILVYbKLd5Yh3lTj70AZR75eoU5d64yHJPHGcTw90uO97WuYdRjlq58D6Um0722PFyNoF8dIt9jlrTGcodX4PnOWPXVe2hVZSjHv/w0yj37198DuWuXmG7ySt4YpjtXoYrpJMZ/D1enrH3t0jeKUiSgqUgSQqWgiQpWAqSpGApSJKCpSBJCpaCJClYCpKkYClIkkLhE80VNviXZHBHaQ4nCcsJ2/mcldhE8wEcJDw6YiOM+YRN5FKrS2yS+j1P/jDKnbrwXpT7/Gc/g3LbcCdwZTpCuWtvvcke9677UI5qn2AT0u2cTegP92+hXGvOJoanoyHK7fVYbmWD7eBe3z6LctSJe9iO5vISO15WZ7uwS2X2/TKbsc9vKWW74ks5+75K08K/ov9X3ilIkoKlIEkKloIkKVgKkqRgKUiSgqUgSQqWgiQpWAqSpGApSJJCKc9zuFVUkvT9zjsFSVKwFCRJwVKQJAVLQZIULAVJUrAUJEnBUpAkBUtBkhQsBUlSKHwB6Kc/9jTKTffeQblSmfVWA9bb7f4c5b70n1dQ7tj6MZQ7tcB2sv7RP38H5T73iZ9Auff/zC+i3MEttiv53z735yj32P2nUK65fQLlVu54COW2zv8Ayi2eZruXh/vsOpimA5SbjY5QLpuw9+PixddQ7puvvIRyT7z3cZS775EfQrnaEtu9fPX1z6Pc81/8S5TbP9xHuTn8fsmmE5RLJ2wX9uFuF+UmvQWU+8O/ZdcB4Z2CJClYCpKkYClIkoKlIEkKloIkKVgKkqRgKUiSgqUgSQqWgiQpFD7RPE8zlBtNWK7eXkS5arWGcpXyFOXu3l5FuWaL9erZO86gHPXw+59EueMX2CTwN178LMqdOc3Oy/b9D6JcfeMcylUXllFuOO6jHLuqkmT3xmWU27nOJp8Pdq6iXDZjk7GtThPljh1jn48r17+OclvHT6LcNpxoTofsfctHbLK4NGATzVnOJsfzEltl32qw81zfrqPcUaOEckXyTkGSFCwFSVKwFCRJwVKQJAVLQZIULAVJUrAUJEnBUpAkBUtBkhQKn2iuVdghD3psYjMbs95qLbRQrlJmk4mb622Uu3LjAOXOvfvHUI469SA9HptAnvXYjuHlDpss3jj/CMoNqmso962vfw3lJiP2Op665wdR7oV/eRbl9q6xneOVjE3UN5vsc3TyTjZZ/ND5u1EurbDrvlZZQTmqU2fXVXU8Rrnh5WsoR/+BIYU/n/uVCsotwO+XrRPr7IEL5J2CJClYCpKkYClIkoKlIEkKloIkKVgKkqRgKUiSgqUgSQqWgiQpFD7RPBmxicOFBnvoUpNNCNbKKcrlGcu1Ftnj/uTP/RTKPfHjH0I5amljC+V23noV5Srw/HV7hyi3+/brKHe9xyZKn3/2WZRbbLEduU/9ym+j3Otf/TLKbW+xidylDptkvXSV7Xyewvdt7cRZlDv/4GMol2QNloOOumz38nDMdhYfjNh5KeXse2g8mqNcP2f/mJD32ffkvSsoVijvFCRJwVKQJAVLQZIULAVJUrAUJEnBUpAkBUtBkhQsBUlSsBQkSaHwieZ5znbQJnM2yVpK2SRhCh+3VGITh80Gm1B95DE2AdqosUlb6tvf+A+UO7j+FspNJmzCsnewj3JXLn4b5fo5261dy0Yot1hlk+jU5jKbQN5YZdfLjZ2bKJfO2PU87PVR7soltkM6Sb6FUv1+D+WePPMgyt3c3UG5tLGJcrfTJZRrtZoot9Bh12mryo7XG7J/BkjnbDK7SN4pSJKCpSBJCpaCJClYCpKkYClIkoKlIEkKloIkKVgKkqRgKUiSQuETzUnCJpDnKZvYrNbYBHKWsgnpacImBLeWV1Hun577AsqtbbFJ0Z//jT9AuVuX3kC5KZycrNXYzt3FNpsUrZbZZHEbTnpvbx5DuVHvAOWoSs6uq9u7eyg3m7LjdZoLKDfts4nm73z9JZS78Rq7riYpmzB/8mc/inIvPv8cymX0ujrFJtGTNvseKjfYDukmnEBeTdiE9L3334lyRfJOQZIULAVJUrAUJEnBUpAkBUtBkhQsBUlSsBQkScFSkCQFS0GSFIrf0TwvoVy9yh66WWUToEmZPW5eWUS5+XSGcnt7bOduf5flqN47bEJ6nrAJ0LXVdZRbObGBcmnGJkCvXWfnJU/YZHu5XOwlPU3ZhGqlxCaz23BSGa4mTyo0CHeTZ1M2AV+Gn3Oqf8gmwqeNIcp1TrDrb9DqolxvziafxwP2O3t96S6UO7bJPpdF8k5BkhQsBUlSsBQkScFSkCQFS0GSFCwFSVKwFCRJwVKQJAVLQZIUCp9oLpfYrt9mo4lyOdyp3G6xnaztDtv1O5yNUW69U0e5Knwd1PRwB+XmZfb8hjU2Gbu1xXbGzqdsAvTCQ6dQ7oV//TLKTXM28UrNS+wjMuoPUG6ps4xydOK/UmLvW3/MrudLN/ZRrtst9nr+5pvXUW7jPPsde3KF7UCe5uzzcbDHrqv6GE62n4Q7x4fwHx0K5J2CJClYCpKkYClIkoKlIEkKloIkKVgKkqRgKUiSgqUgSQqWgiQplPI8Z8tbJUnf97xTkCQFS0GSFCwFSVKwFCRJwVKQJAVLQZIULAVJUrAUJEnBUpAkhcJ3NH/6o0+hXPfaGyhXaS6iXLvNdjRXanD3bY0NelcrbCdrrcae3y998u9R7tnf/1WUW15ij3tzl+18vvuBR1Fu8/Q5lLt2aw/lZsNDlOvvsl2/T/36n6Dcp555EuX2bt5AueXlDswtoVyWzVDujTcvsdxldp7LDXZdPfsyOy+//GG2+/vOB9h5aayyndRH+yw3PZig3MnNNZR7+IF3o9ylS12U+8hvfQHlCO8UJEnBUpAkBUtBkhQsBUlSsBQkScFSkCQFS0GSFCwFSVKwFCRJofCJ5q0N1jOz27dRbpSxyeLBAMWSvJyiXLXKJpWXltZRrl5jx6NGgyOUa8EJ7mTKci+98ALK3XWBTUhfvXoT5crlEsotNIo9z5VKA+VaLTZ5P+gPUW40Yrk0naLcYou9jicevYByzQ6bLKYeOncG5bIZPH9X2KRyuddEuc0FNon+6PkH2PFWtlDu5RtsEr1I3ilIkoKlIEkKloIkKVgKkqRgKUiSgqUgSQqWgiQpWAqSpGApSJJC4RPNZ07XUW65xCYJL15ho8o7u3OUm2ZssnNxkU3GDuDu4GzeRzmqd8Qmgfd32eR4r88mvcezLspVcnZeOourKLdzcx/lrg7YJCu1e4udv60NNtlemrOdygfdA5RrtNnnaAXuhq5X2O/EyTRDOWoZ/oPAYMKe37TPjtees+Pdffo4yp3YZtfBlats4v/2LpvgLpJ3CpKkYClIkoKlIEkKloIkKVgKkqRgKUiSgqUgSQqWgiQpWAqSpFD4RPPSKpskHMFJvdXNCnvgdhvF9nYmKDeessnTap3tqp2yVbrYYMCe3yxjr/dwxCaG23DX73jIJotH4z2Um87YBG0Gc9R8xnaE94/Y9by01IK5ZZSju5z3brP3d3GR7ZoulYv9PTlL2fVcr7Lz12CD3km9zr5fzt59FuVGQ3a9fOUr30a5/3qDTT4XyTsFSVKwFCRJwVKQJAVLQZIULAVJUrAUJEnBUpAkBUtBkhQsBUlSKHyiudpkh2wusV3Oa4ust6ojNkFba7FdzkcH8NRk7Pm1mpvseFBz4RjKZZMuytUX2OutVdn7VqksoNwkh7u1Z2wkPM9LKEeV2IBqkk/Z9ZfBFdI1uLM4qbMJ8+4Bm2gewUn+5RU2cU2lOTvRZXj9DRO2c3xn7wjlDuAO896A7Sb/0vOvotxNtqK+UN4pSJKCpSBJCpaCJClYCpKkYClIkoKlIEkKloIkKVgKkqRgKUiSQuETzf0+nMSssF2wi206qcwmIttweevyMpu0pbt5+0fF7lo9HN5EudmYTWJ26mxCullj7286Ybuhq1X2u6QOf77UGnCnN7TQYsdbWGQfpTL8xKUZe9/qLXbApRU2Yb6/30O5HpxEp+hu7WHKJtu/8zbb/f3aN6+g3NYam+DeOsXOc1Jm529jpcOOVyDvFCRJwVKQJAVLQZIULAVJUrAUJEnBUpAkBUtBkhQsBUlSsBQkSaHwiearl1lu0mWTxZ0NNtnZbMHdsmyQOllbY6emP2ATzd0uy1EbW32UO7jNjleZs9c7h7t0s4xNqCZzlqO/XkrlYnc012vsvIzgru6cXc5Jbc6u53TI3uBsxK6/DO6G7vaLvZ73dtkE8v7RCOXevsjOy8Eeex3TAbtOt5e3Ue7eO06iHHy5hfJOQZIULAVJUrAUJEnBUpAkBUtBkhQsBUlSsBQkScFSkCQFS0GSFAqfaM5qbNfvrP4elJvM2a7fcsomIpvLbOJ1ZYNNXK+W2Yjq2rDYnbbnHrwP5bp7bMfwaMAuhSyto1ySs98b85Sdl/GI7equ1+Hzg9ZPn0O53pi9jlEf7hzP2S7iTpnt8J2Xj1BuNmPXQaPNJtup5jKb8F2ps/NyV7KCcg8+zP7i4MJDD6Pc2bvvRrnH38smqa9eZ/9cUCTvFCRJwVKQJAVLQZIULAVJUrAUJEnBUpAkBUtBkhQsBUlSsBQkSaGU53DpriTp+553CpKkYClIkoKlIEkKloIkKVgKkqRgKUiSgqUgSQqWgiQpWAqSpGApSJKCpSBJCpaCJClYCpKkYClIkoKlIEkKloIkKVgKkqRgKUiSgqUgSQr/DSWxH3+U5AHDAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 16, 192])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unfolded = patching(img_batch)\n",
    "visualize_patches(unfolded[0], 8, nrow=4) # visualize fist sequence from batch\n",
    "unfolded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layer_norm1= nn.LayerNorm(256)\n",
    "        self.layer_norm2= nn.LayerNorm(256)\n",
    "\n",
    "        self.linear1 = nn.Linear(256, 512)\n",
    "        self.linear2 = nn.Linear(512, 256)\n",
    "\n",
    "        self.attention = nn.MultiheadAttention(256, 8)\n",
    "\n",
    "        self.gelu = nn.GELU()\n",
    "        self.dropout = nn.Dropout()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x_residual1 = self.layer_norm1(x)\n",
    "\n",
    "        x_attention, attention_weights = self.attention(x, x, x)\n",
    "        x_residual2 = x_residual1 + x_attention\n",
    "\n",
    "        x = self.layer_norm2(x_residual2)\n",
    "\n",
    "        x = self.linear1(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.linear2(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x += x_residual2\n",
    "\n",
    "        return x\n",
    "\n",
    "class VIT(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear = nn.Linear(192, 256)\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, 256))\n",
    "        self.pos_encoding = nn.Parameter(torch.randn(1, 17, 256))\n",
    "\n",
    "\n",
    "        self.transformers = nn.ModuleList([\n",
    "            Transformer() for _ in range(6)\n",
    "        ])\n",
    "\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.layer_norm = nn.LayerNorm(256)\n",
    "        self.linear_decision = nn.Linear(256, 10)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = torch.column_stack((self.cls_token.repeat(16, 1, 1), x))\n",
    "        x = x.reshape(16, 17, 256)\n",
    "        x += self.pos_encoding\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        for transformer in self.transformers:\n",
    "            x = transformer(x)\n",
    "\n",
    "        cls_token = x[:, 0, :]\n",
    "\n",
    "        final = self.layer_norm(cls_token)\n",
    "        final = self.linear_decision(final)\n",
    "        return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 10])"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vit = VIT().to(\"mps\")\n",
    "out = vit(unfolded.to(\"mps\"))\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3219722"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in vit.parameters())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
